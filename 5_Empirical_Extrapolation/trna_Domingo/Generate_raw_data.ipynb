{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /home/siliang/usr/miniconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In /home/siliang/usr/miniconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The verbose.level rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In /home/siliang/usr/miniconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The verbose.fileo rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.random as nrand\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "import copy\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.linalg import hadamard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sequence(sequences):\n",
    "    BASES = np.asarray(['A','T','C','G'])\n",
    "    shape = sequences.shape\n",
    "    data = sequences[..., None] == BASES\n",
    "    return data.reshape(shape[0], shape[1] * BASES.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fitness(read_count_in, read_count_out, in_idx, out_idx):\n",
    "    OD_out = np.array([\n",
    "        [1.39,1.21,1.30],\n",
    "        [1.17,1.23,1.14]\n",
    "    ])\n",
    "    OD_innitial = 0.015\n",
    "    wt_read_count_in = df_all[f'reads_IN_{in_idx}'][0]\n",
    "    wt_read_count_out = df_all[f'reads_OUT_{in_idx}{out_idx}'][0]\n",
    "    total_read_count_in = df_all[f'reads_IN_{in_idx}'].sum()\n",
    "    total_read_count_out = df_all[f'reads_OUT_{in_idx}{out_idx}'].sum()\n",
    "    \n",
    "    f_in = OD_innitial*read_count_in/total_read_count_in\n",
    "    f_out = OD_out[in_idx-1,out_idx-1]*read_count_out/total_read_count_out\n",
    "    \n",
    "    f_in_wt = OD_innitial*wt_read_count_in/total_read_count_in\n",
    "    f_out_wt = OD_out[in_idx-1,out_idx-1]*wt_read_count_out/total_read_count_out\n",
    "    \n",
    "    n = np.log2(f_out/f_in) # number of generation\n",
    "    n_wt = np.log2(f_out_wt/f_in_wt)\n",
    "    \n",
    "    return np.log(n/n_wt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('trna_Domingo_data.csv')\n",
    "seqs_raw = df_all.seq.to_numpy()\n",
    "seqs_raw = np.array(list(map(list,seqs_raw)))\n",
    "seqs = seqs_raw[:,np.array([1,2,6,27,43,46,66,69,70,71])-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = load_sequence(seqs)\n",
    "x = x[:,np.where((x != x[0]).sum(axis=0) > 0)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate fitness\n",
    "\n",
    "fitness_dict = {f'Fit{i+1}{j+1}':[] for i in range(2) for j in range(3)}\n",
    "for idx, row in df_all.iterrows():\n",
    "    for in_idx in [1,2]:\n",
    "        for out_idx in [1,2,3]:\n",
    "            read_count_in = row[f'reads_IN_{in_idx}']\n",
    "            read_count_out = row[f'reads_OUT_{in_idx}{out_idx}']\n",
    "            fitness = get_fitness(read_count_in, read_count_out, in_idx, out_idx)\n",
    "            fitness_dict[f'Fit{in_idx}{out_idx}'].append(fitness)\n",
    "\n",
    "fitness_df = pd.DataFrame(fitness_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose genotype subspace.\n",
    "# 0:G/A 1:U/G; 2:G/U; 3:C/U, 4:A/C, 5:C/U; 6:C/U; 7:A/G; 8:G/U; 9:C/U; with only 1 missing genotype \n",
    "# 1,2,6,8 are tri-allelic\n",
    "seqs_sub = seqs[(seqs[:,1] != 'C') & (seqs[:,2] != 'A') & (seqs[:,6] != 'A') & (seqs[:,8] != 'A')]\n",
    "fitness_df_sub = fitness_df[(seqs[:,1] != 'C') & (seqs[:,2] != 'A') & (seqs[:,6] != 'A') & (seqs[:,8] != 'A')]\n",
    "seqs_sub = (seqs_sub != ['G','U','G','C','A','C','C','A','G','C']).astype(int)\n",
    "seq_fit_dict = {''.join(seqs_sub[i].astype('str')): fitness_df_sub.iloc[i].to_list() for i in range(len(seqs_sub))}\n",
    "\n",
    "N=10\n",
    "landscape_list_b = []\n",
    "for i in range(2**N):\n",
    "    seq_b = [int(x) for x in bin(i)[2:]]\n",
    "    seq_b = [0]*(N-len(seq_b))+seq_b\n",
    "    landscape_list_b.append(seq_b)\n",
    "landscape_list_b = np.array(landscape_list_b)\n",
    "\n",
    "fitness_df_sub_ordered = {'Seq':[],'Fit11':[],'Fit12':[],'Fit13':[],'Fit21':[],'Fit22':[],'Fit23':[]}\n",
    "for seq in landscape_list_b:\n",
    "    seq_str = ''.join(seq.astype('str'))\n",
    "    if seq_str in seq_fit_dict:\n",
    "        r1,r2,r3,r4,r5,r6 = seq_fit_dict[seq_str]\n",
    "        fitness_df_sub_ordered['Seq'].append(seq_str)\n",
    "        fitness_df_sub_ordered['Fit11'].append(r1)\n",
    "        fitness_df_sub_ordered['Fit12'].append(r2)\n",
    "        fitness_df_sub_ordered['Fit13'].append(r3)\n",
    "        fitness_df_sub_ordered['Fit21'].append(r4)\n",
    "        fitness_df_sub_ordered['Fit22'].append(r5)\n",
    "        fitness_df_sub_ordered['Fit23'].append(r6)\n",
    "    else:\n",
    "        fitness_df_sub_ordered['Seq'].append(seq_str)\n",
    "        fitness_df_sub_ordered['Fit11'].append(-1)\n",
    "        fitness_df_sub_ordered['Fit12'].append(-1)\n",
    "        fitness_df_sub_ordered['Fit13'].append(-1)\n",
    "        fitness_df_sub_ordered['Fit21'].append(-1)\n",
    "        fitness_df_sub_ordered['Fit22'].append(-1)\n",
    "        fitness_df_sub_ordered['Fit23'].append(-1)\n",
    "        \n",
    "fitness_df_sub_ordered = pd.DataFrame(fitness_df_sub_ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interopolate missing fitness estimations using linear model\n",
    "for rep in ['Fit11','Fit12','Fit13','Fit21','Fit22','Fit23']:\n",
    "    _y = fitness_df_sub[rep].to_numpy()\n",
    "    _x = seqs_sub\n",
    "    reg = Ridge(fit_intercept=True).fit(_x, _y)\n",
    "    y_predict = reg.predict(landscape_list_b)\n",
    "    missing_idx_list = np.where(fitness_df_sub_ordered[rep] == -1)[0]\n",
    "    fitness_df_sub_ordered.loc[missing_idx_list,rep] = y_predict[missing_idx_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the parameter to select different ruggedness measure\n",
    "metric = 'r_s' # 'N_max','epi','r_s','open_ratio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if metric in ['N_max','gamma']:\n",
    "    with open('../../index_file/trna_Domingo_neighbor_list.pkl','rb') as f:\n",
    "        neighbor_list = pickle.load(f)\n",
    "\n",
    "if metric in ['epi','gamma']:\n",
    "    with open('../../index_file/trna_Domingo_epi_square_list.pkl','rb') as f:\n",
    "        epi_square_list = pickle.load(f)\n",
    "    \n",
    "elif metric == 'open_ratio':\n",
    "    with open('../../index_file/trna_Domingo_pathway_list_4steps_all.pkl','rb') as f:\n",
    "        pathway_list = pickle.load(f)\n",
    "    _y = df_all.fitness.to_numpy()\n",
    "    y20,y80 = np.percentile(_y,[20,80])\n",
    "    filtered_ascend = (_y[pathway_list[:,0]]<=y20) & (_y[pathway_list[:,-1]]>=y80)\n",
    "    filtered_descend = (_y[pathway_list[:,0]]>=y80) & (_y[pathway_list[:,-1]]<=y20)\n",
    "    pathway_list = pathway_list[filtered_ascend|filtered_descend,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_N_max(y):\n",
    "    N_max = 0\n",
    "    for i in range(len(y)):\n",
    "        fit = y[i]\n",
    "        if np.sum(fit <= y[neighbor_list[i]])==0:\n",
    "            N_max += 1\n",
    "    return N_max\n",
    "\n",
    "def cal_epi(y):\n",
    "    epi_fit_list = y[epi_square_list]\n",
    "    n_epi = np.sum(np.sum(epi_fit_list[:,[0,0,3,3]] > epi_fit_list[:,[1,2,1,2]],axis=1)==4)\n",
    "    n_epi += np.sum(np.sum(epi_fit_list[:,[0,0,3,3]] < epi_fit_list[:,[1,2,1,2]],axis=1)==4)\n",
    "    return n_epi/len(epi_fit_list)\n",
    "\n",
    "def cal_r_s(y):\n",
    "    # x is a global variable with each row being a one-hot encode sequence for the corresponding genotype.\n",
    "    reg = Ridge(fit_intercept=True).fit(x, y)\n",
    "    y_predict = reg.predict(x)\n",
    "    roughness = np.sqrt(np.mean(np.square(y - y_predict)))\n",
    "    slope = np.mean(np.abs(reg.coef_))\n",
    "    return roughness/slope\n",
    "\n",
    "def cal_open_ratio(y):\n",
    "    diff = y[pathway_list[:,:-1]] - y[pathway_list[:,1:]] \n",
    "    open_descend = np.sum(np.sum(diff >= 0,axis=1) == pathway_list.shape[1]-1)\n",
    "    open_ascend = np.sum(np.sum(diff <= 0,axis=1) == pathway_list.shape[1]-1)\n",
    "    total_open = open_descend + open_ascend\n",
    "    return total_open/len(pathway_list)\n",
    "\n",
    "def cal_E(y):\n",
    "    global idx_1, phi\n",
    "    W = y.astype('float32')\n",
    "    E = phi.dot(W)/(2**N)\n",
    "    E_square = np.square(E)\n",
    "    E_sum = E_square.sum()-E_square[0]\n",
    "    E_1 = E_square[idx_1].sum()\n",
    "    #E_2 = E_square[idx_2].sum()\n",
    "    #F_2 = E_2/E_sum\n",
    "    F_sum = (E_sum-E_1)/E_sum\n",
    "    return F_sum\n",
    "\n",
    "def cal_gamma(y):\n",
    "    cov = np.sum((y[epi_square_list][:,1]-y[epi_square_list][:,0])*(y[epi_square_list][:,3]-y[epi_square_list][:,2])) +\\\n",
    "    np.sum((y[epi_square_list][:,2]-y[epi_square_list][:,0])*(y[epi_square_list][:,3]-y[epi_square_list][:,1]))\n",
    "    cov = cov/(2*epi_square_list.shape[0])\n",
    "    sg_list = []\n",
    "    for i in range(len(y)):\n",
    "        for neighbor_idx in neighbor_list[i]:\n",
    "            sg_list.append(y[neighbor_idx] - y[i])\n",
    "    var = np.var(sg_list)\n",
    "    return cov/var\n",
    "\n",
    "def cal_adptwalk_steps(y):\n",
    "    N_step_list = []\n",
    "    for idx_0 in range(len(y)):\n",
    "        idx_current = idx_0\n",
    "        N_step = 0\n",
    "        while True:\n",
    "            fit_current = y[idx_current]\n",
    "            neighbor = neighbor_list[idx_current]\n",
    "            if len(neighbor) == 0 :\n",
    "                if N_step > 0: N_step_list.append(N_step)\n",
    "                break\n",
    "            fit_next = y[neighbor].max()\n",
    "            if fit_next <= fit_current:\n",
    "                if N_step > 0: N_step_list.append(N_step)\n",
    "                break\n",
    "            idx_next = neighbor[np.argmax(y[neighbor])]\n",
    "            N_step += 1\n",
    "            idx_current = idx_next\n",
    "    return np.mean(N_step_list)\n",
    "\n",
    "def cal_adptwalk_probs(y):\n",
    "    idx_GO = np.argmax(y)\n",
    "    N_reach = 0\n",
    "    N_total = 0\n",
    "    for idx_0 in range(len(y)):\n",
    "        idx_current = idx_0\n",
    "        N_step = 0\n",
    "        while True:\n",
    "            fit_current = y[idx_current]\n",
    "            neighbor = neighbor_list[idx_current]\n",
    "            if len(neighbor) == 0:\n",
    "                if N_step > 0: N_total += 1\n",
    "                break\n",
    "            fit_next = y[neighbor].max()\n",
    "            if fit_next <= fit_current:\n",
    "                if N_step > 0:\n",
    "                    N_total += 1\n",
    "                    if idx_current == idx_GO:\n",
    "                        N_reach += 1\n",
    "                break\n",
    "            idx_next = neighbor[np.argmax(y[neighbor])]\n",
    "            N_step += 1\n",
    "            idx_current = idx_next\n",
    "    return N_reach/N_total\n",
    "\n",
    "\n",
    "if metric == 'N_max':\n",
    "    get_ruggedness = get_N_max\n",
    "\n",
    "elif metric == 'epi':\n",
    "    get_ruggedness = cal_epi\n",
    "\n",
    "elif metric == 'r_s':\n",
    "    get_ruggedness = cal_r_s\n",
    "\n",
    "elif metric == 'open_ratio':\n",
    "    get_ruggedness = cal_open_ratio\n",
    "\n",
    "elif metric == 'E':\n",
    "    N=10\n",
    "    landscape_list_b = []\n",
    "    for i in range(2**N):\n",
    "        seq_b = [int(x) for x in bin(i)[2:]]\n",
    "        seq_b = [0]*(N-len(seq_b))+seq_b\n",
    "        landscape_list_b.append(seq_b)\n",
    "    landscape_list_b = np.array(landscape_list_b)\n",
    "    get_ruggedness = cal_E\n",
    "    phi = hadamard(2**N,dtype='float32')\n",
    "    idx_1 = landscape_list_b.sum(axis=1) == 1\n",
    "\n",
    "elif metric == 'gamma':\n",
    "    get_ruggedness = cal_gamma\n",
    "    \n",
    "elif metric == 'adptwalk_steps':\n",
    "    get_ruggedness = cal_adptwalk_steps\n",
    "    \n",
    "elif metric == 'adptwalk_probs':\n",
    "    get_ruggedness = cal_adptwalk_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\r",
      "2\r",
      "3\r",
      "4\r",
      "5\r",
      "6\r"
     ]
    }
   ],
   "source": [
    "duplicates_list = ['Fit11','Fit12','Fit13','Fit21','Fit22','Fit23']\n",
    "res_dict = {i:[] for i in range(1,7)}\n",
    "for replication in range(1,7):\n",
    "    print(replication,end='\\r')\n",
    "    if replication == 1:\n",
    "        for duplicate in duplicates_list:\n",
    "            if metric == 'E':\n",
    "                y = fitness_df_sub_ordered[duplicate].to_numpy()\n",
    "            else:\n",
    "                y = fitness_df[duplicate].to_numpy()\n",
    "            res_dict[replication].append(get_ruggedness(y))\n",
    "    else:\n",
    "        iter_list = combinations(duplicates_list,replication)   \n",
    "        for duplicate in iter_list:\n",
    "            if metric == 'E':\n",
    "                y = fitness_df_sub_ordered[list(duplicate)].mean(axis=1).to_numpy()\n",
    "            else:\n",
    "                y = fitness_df[list(duplicate)].mean(axis=1).to_numpy()\n",
    "            res_dict[replication].append(get_ruggedness(y))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment only if you want to overwrite trna_raw_data folder.\n",
    "# with open(f'./trna_Domingo_{metric}_plot.pkl','wb') as f:\n",
    "#     pickle.dump(res_dict,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
